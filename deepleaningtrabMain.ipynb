{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\nimport timm\nimport time","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T17:41:11.102574Z","iopub.execute_input":"2024-11-15T17:41:11.103078Z","iopub.status.idle":"2024-11-15T17:41:11.110267Z","shell.execute_reply.started":"2024-11-15T17:41:11.103033Z","shell.execute_reply":"2024-11-15T17:41:11.108892Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T17:41:17.243348Z","iopub.execute_input":"2024-11-15T17:41:17.243803Z","iopub.status.idle":"2024-11-15T17:41:17.251362Z","shell.execute_reply.started":"2024-11-15T17:41:17.243762Z","shell.execute_reply":"2024-11-15T17:41:17.249534Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Configurações iniciais\nbatch_size = 64\nlearning_rate = 0.001\nnum_epochs = 10\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Transformação do dataset\ntransform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),  # Converte para 3 canais\n    transforms.Resize((128, 128)),  # Redimensiona para 224x224\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Carregamento do dataset Fashion-MNIST\ntrain_dataset = datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\ntest_dataset = datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Função de treinamento\ndef train(model, loader, criterion, optimizer):\n    model.train()\n    total_loss = 0\n    for images, labels in loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n    return total_loss / len(loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Função de avaliação\ndef evaluate(model, loader):\n    model.eval()\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n    accuracy = correct / total\n    return accuracy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Função principal para treinar e avaliar os modelos\ndef train_and_evaluate(model_name, pre_training):\n    # Carrega o modelo do timm e ajusta para 10 classes (Fashion-MNIST)\n    model = timm.create_model(model_name, pretrained=pre_training, num_classes=10).to(device)\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n    print(f\"\\nTreinando o modelo: {model_name}\")\n    start_time = time.time()\n\n    for epoch in range(num_epochs):\n        train_loss = train(model, train_loader, criterion, optimizer)\n        test_accuracy = evaluate(model, test_loader)\n        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n\n    end_time = time.time()\n    print(f\"Tempo total de treinamento para {model_name}: {(end_time - start_time) / 60:.2f} minutos\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pre_trained_model = 'tf_efficientnetv2_s.in21k'  # EfficientNetV2\n#raw_model = 'efficientnetv2_s'\n\ntrain_and_evaluate(pre_trained_model, pre_training=True)\n\nprint(f\"FINALIZADO {pre_trained_model}\\n\")\n\n#train_and_evaluate(raw_model, pre_training=False)\n\n#print(f\"FINALIZADO {raw_model}\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}